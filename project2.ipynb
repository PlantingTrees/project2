{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy scikit-learn requests matplotlib.pyplot seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code is to parse violation time column i tried using the data as is but I couldnt see any pattern on the scatterplot. Since time move from morning (AM) to Night (PM) i think it would be best to parse and sort the violation time data; hopefully it gives us a better visualization \n",
    "def parse_violation_time(time_str):\n",
    "    '''Handles parsing time(AM/PM)'''\n",
    "    try:\n",
    "        if time_str[-1] == 'A':\n",
    "            new_time_str=time_str + 'M'\n",
    "            return datetime.strptime(new_time_str, '%I%M%p')\n",
    "        elif time_str[-1] == 'P':\n",
    "            new_time_str=time_str + 'M'\n",
    "            if time_str[:2] <= '12':\n",
    "                return datetime.strptime(new_time_str, '%I%M%p')\n",
    "            else:\n",
    "                return datetime.strptime(new_time_str, '%I%M%p')\n",
    "        elif len(time_str) == 4:\n",
    "            return datetime.strptime(new_time_str, '%H%M')\n",
    "        else:\n",
    "            return pd.NaT\n",
    "    except ValueError:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response= requests.get(\"https://data.cityofnewyork.us/resource/2bnn-yakx.json\")\n",
    "response_json= response.json()\n",
    "df = pd.DataFrame(response_json)\n",
    "\n",
    "#--------------------------Nahallah Champagne: Data Collection and Preprocessing--------------------#\n",
    "\n",
    "#Load dataset into DataFrame\n",
    "#vehicle_df = pd.read_csv('Parking_Violations_Issued_-_Fiscal_Year_2024_20240415.csv')\n",
    "\n",
    "#Drop these columns from the Vehicle Collisions Dataset. Since most of the cells in these columns are empty or not relevent. \n",
    "df = df.drop('date_first_observed', axis=1) #axis 1 = colunms\n",
    "df = df.drop('sub_division', axis=1) \n",
    "df = df.drop('intersecting_street', axis=1)\n",
    "#df = df.drop('double_parking_violation', axis=1)\n",
    "# df = df.drop('hydrant_violation', axis=1)                     # I ran on my end it said that it didnt exist so i commented off to run the code\n",
    "# df = df.drop('no_standing_or_stopping_violation', axis=1)\n",
    "# df = df.drop('violation_description', axis=1)\n",
    "\n",
    "#I want to stort the data in some way, sorting it in decsending order by year seems like a good idea. \n",
    "df = df.sort_values(by='issue_date', ascending=False)\n",
    "\n",
    "#Display the first 5 rows of the specific rows\n",
    "df.head()\n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#describe data \n",
    "# df['vehicle_body_type'].describe(include='all')\n",
    "# df['from_hours_in_effect'].describe(include='all')\n",
    "df.describe(include='all') \n",
    "plt.figure(figsize=(12,6))\n",
    "vehicle_counts=df['vehicle_body_type'].value_counts()\n",
    "vehicle_counts.plot(kind='bar')\n",
    "plt.title(\"Violations by Body-types\")\n",
    "plt.xlabel('Vehicle Body type')\n",
    "plt.ylabel(\"Number of Occurrences\")\n",
    "\n",
    "\n",
    "#using the time parser on violation times (this is for the scatter plot, may not be nessary for visuals we already have a bar and histogram but maybe for Training)\n",
    "df['violation_time']= df['violation_time'].apply(parse_violation_time)\n",
    "df['violation_time'] = df['violation_time'].dt.time \n",
    "#getting a slice of times and their counts\n",
    "top_times= df['violation_time'].value_counts().head(80)\n",
    "plt.figure(figsize=(12,6))\n",
    "top_times.plot(kind='bar', color='salmon')\n",
    "plt.title(\"Violations by Times\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#VIOLATION LOCATION GRAPH\n",
    "plt.figure(figsize=(12,6))\n",
    "violation_location=df['violation_location'].value_counts() \n",
    "violation_location.plot(kind='bar')\n",
    "plt.title(\"Violations by Locations\")\n",
    "plt.xlabel('Postal Code (100) affixed')\n",
    "plt.ylabel(\"Number of Occurrences by Postal code\")  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Nahallah Champagne: Data Visualization-----------------------------------#\n",
    "'''\n",
    "import pandas as pd   \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "#------Histogram-----\n",
    "\n",
    "# Specific vehicle makes for the histogram\n",
    "specific_vehicles = ['NISSAN', 'HONDA', 'NISSA', 'JEEP', 'BMW', 'FORD', 'LEX']\n",
    "\n",
    "# Only include rows that have vehicle_make column filled\n",
    "specific_vehicle_df = df[df['vehicle_make'].isin(specific_vehicles)]\n",
    "\n",
    "# Plot histogram for vehicle make\n",
    "plt.figure(figsize=(12, 6))\n",
    "specific_vehicle_df['vehicle_make'].value_counts().plot(kind='bar', color='salmon')\n",
    "\n",
    "# Plot data in box chart\n",
    "plt.title('Frequency of Vehicle Make Tickets')\n",
    "plt.xlabel('Vehicle Make')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show() \n",
    "\n",
    "#---------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'column_name' is the name of the column you're interested in\n",
    "unique_counties = df['violation_county'].dropna().unique() # i removed nan's cuz i noticed nan skewed the data\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique county:\", unique_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'column_name' is the name of the column you're interested in\n",
    "# COnverting vehicle year to int cuz some ML cannot handle strings\n",
    "df = df[df['vehicle_year'].replace('0', np.nan).notna()]\n",
    "\n",
    "v_= (df['vehicle_year']).astype(int)\n",
    "unique_vehicle_year= v_.unique()\n",
    "# Print the result\n",
    "print(\"Number of unique vehicle year:\", unique_vehicle_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'column_name' is the name of the column you're interested in\n",
    "df= df[df['violation_location'].notna()]\n",
    "unique_location = df['violation_location'].unique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique instances:\", unique_location)\n",
    "#This might have too many unique instances, but I will see\n",
    "#these are the postal codes, generally they will be unique just need to remove these pesky 'nan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'column_name' is the name of the column you're interested in\n",
    "unique_body_type = df['vehicle_body_type'].unique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique instances:\", unique_body_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------Nahallah Champagne: Multiple Linear Regression/Using encoding-------------------------#\n",
    "#STILL DEBATING IF I AM GOING TO USE THIS MODEL\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Here i will encode categorical variables using one-hot encoding. Changing the values to binary\n",
    "df_encoded = pd.get_dummies(df, columns=['source'], drop_first=True)\n",
    "\n",
    "# Encode the 'group' column as well\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['group_encoded'] = label_encoder.fit_transform(df['group'])\n",
    "\n",
    "# Split the data into x and y variables\n",
    "X = df_encoded[['year'] + list(df_encoded.filter(regex='source_').columns)]\n",
    "y = df_encoded['group_encoded']\n",
    "\n",
    "# Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the linear regression model!!\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the test sets\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "#------------------------------------------Nahallah Champagne: R and r2 values--------------------------------------\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r_squared)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------Nahallah Champagne: First Machine Learning Model: Perceptron------------------------#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset and extract colunms from the DataFrame\n",
    "X = df[['vehicle_body_type', 'vehicle_year']].values  \n",
    "y = df['violation_county'].values\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X.shape)\n",
    "print('Class labels:', np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from category_encoders import TargetEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Preprocess data\n",
    "Features = df[['vehicle_color', 'vehicle_body_type', 'vehicle_year', 'vehicle_make', 'violation_time', 'violation_county']]\n",
    "Target = df['violation_code']\n",
    "\n",
    "# Split data into train and test sets\n",
    "Features_train, Features_test, Target_train, Target_test = train_test_split(Features, Target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['vehicle_color', 'vehicle_body_type', 'vehicle_make', 'violation_county']\n",
    "numerical_cols = ['vehicle_year']\n",
    "\n",
    "# Create column transformers\n",
    "categorical_transformer = ColumnTransformer(transformers=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['vehicle_body_type', 'violation_county']),\n",
    "    ('target', TargetEncoder(cols=['vehicle_color', 'vehicle_make']), ['vehicle_color', 'vehicle_make'])\n",
    "])\n",
    "\n",
    "numerical_transformer = 'passthrough'\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', categorical_transformer, categorical_cols),\n",
    "    ('num', numerical_transformer, numerical_cols)\n",
    "])\n",
    "\n",
    "# Encode features\n",
    "Features_train_encoded = preprocessor.fit_transform(Features_train, Target_train)\n",
    "Features_test_encoded = preprocessor.transform(Features_test)\n",
    "\n",
    "# Create Random Forest pipeline\n",
    "rf_model = Pipeline(steps=[\n",
    "    ('randomforest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(Features_train_encoded, Target_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(Features_test_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(Target_test, y_pred))\n",
    "print('Precision:', precision_score(Target_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(Target_test, y_pred, average='weighted'))\n",
    "print('F1-score:', f1_score(Target_test, y_pred, average='weighted'))\n",
    "print('\\nClassification Report:\\n', classification_report(Target_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset caputures ticket given to car for the fiscal year 2023, we looked into the violation times, what body types we more substible to being ticketed and in what county said tickets were given.\n",
    "Our main training data features are {violation time, location and bodytypes}\n",
    "## **Our hypothesis: Given a car of 'bodytype', located in a certain county at some predefined time, could we train a machine to determine what violation code would such car violate.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing a scaatter plot of the bodytypes with  time sanity check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
